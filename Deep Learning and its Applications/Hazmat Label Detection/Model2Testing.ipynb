{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Libraries\n",
    "from skimage.io import imshow, imread\n",
    "from skimage.transform import rescale, resize\n",
    "import os\n",
    "import numpy as np\n",
    "from PIL import ImageFile\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This code is initially used to generate X.npy and Y.npy\n",
    "\n",
    "# samples = []\n",
    "# truths = []\n",
    "# for folder in os.listdir(\"HTLID\"):\n",
    "#     for subfolder in os.listdir(\"HTLID/{}\".format(folder)):\n",
    "#         i = 0\n",
    "#         for name in os.listdir(\"HTLID/{}/{}\".format(folder, subfolder)):\n",
    "#             samples.append(\"HTLID/\" + folder + \"/\" + subfolder + \"/\" + name)\n",
    "#             if name[len(name)-9:len(name)] != \"_mask.png\":\n",
    "#                 if name[0:2] == 'co':\n",
    "#                     truths.append(48)\n",
    "#                 elif name[0:2] == 'da':\n",
    "#                     truths.append(46)\n",
    "#                 elif name[0:2] == 'ex':\n",
    "#                     truths.append(0)\n",
    "#                 elif name[0:2] == 'fl':\n",
    "#                     truths.append(45)\n",
    "#                 elif name[0:2] == 'no':\n",
    "#                     truths.append(43)\n",
    "#                 elif name[0:2] == 'or':\n",
    "#                     truths.append(50)\n",
    "#                 elif name[0:2] == 'ox':\n",
    "#                     truths.append(49)\n",
    "#                 else:\n",
    "#                     truths.append(55)\n",
    "\n",
    "# print(len(samples))\n",
    "# masks=[]\n",
    "# i = 0\n",
    "# while i < len(samples):\n",
    "#     if samples[i][len(samples[i])-9:len(samples[i])] == \"_mask.png\":\n",
    "#         masks.append(samples[i])\n",
    "#         samples.remove(samples[i])\n",
    "#         i -= 1\n",
    "#     i += 1\n",
    "# Y = keras.utils.to_categorical(truths, num_classes = 63)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y=np.load(\"Y.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# X=[]\n",
    "# I = np.linspace(0, 3455, 3456, dtype=np.float64).reshape(3456,1)\n",
    "# J = np.linspace(0, 5183, 5184, dtype=np.float64).reshape(1, 5184)\n",
    "# for l in range(0, 600):\n",
    "#     img = imread(masks[l])\n",
    "#     actual = imread(masks[l][0:len(masks[l])-9] + \".jpg\")\n",
    "#     i = int(np.sum(I*img)/np.sum(img))\n",
    "#     j = int(np.sum(J*img)/np.sum(img))\n",
    "#     i_max = np.max(np.argmax(img*I, axis=0))\n",
    "#     j_max = np.max(np.argmax(img*J, axis=1))\n",
    "#     _from = int(np.max((i_max - i, j_max - j)))\n",
    "#     cut = actual[(i - _from):(i + _from),(j - _from):(j + _from)]\n",
    "#     img_in = resize(cut, (128,128))\n",
    "#     X.append(img_in)\n",
    "#     print(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.load(\"X.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prevent Memory Hog\n",
    "from keras.backend.tensorflow_backend import set_session\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth=True\n",
    "set_session(tf.Session(config=config))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model trained by Model2Training\n",
    "from keras.models import load_model\n",
    "model = load_model('one_pic7_1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600/600 [==============================] - 3s 5ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.564058409134547, 0.8083333325386047]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#\n",
    "model.evaluate(X, Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This model has a loss of 0.56, and an accuracy of 80.8%"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
